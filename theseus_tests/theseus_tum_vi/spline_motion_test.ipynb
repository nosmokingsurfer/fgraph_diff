{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import theseus as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from spline_generation import generate_batch_of_splines\n",
    "from spline_dataloader import Spline_2D_Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple MLP model for initial tests\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hid_size=30, use_offset=False):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, out_size, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_):\n",
    "        return self.fc(state_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "Generating 2d data - moving along spline curve on a 2D plane.\n",
    "\n",
    "Generatint batch of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_splines = \"./splines/\"\n",
    "\n",
    "B = 4 # number of splines in batch\n",
    "n_batch = 1 # number of batches to generate\n",
    "n_control_points = 10 # number of control points in spline. Matches number of poses in optimization problem\n",
    "n_pts_spline_segment = 100 # number of points for each spline segment during interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_batch_of_splines(path_to_splines, B*n_batch, n_control_points, n_pts_spline_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "dataset = Spline_2D_Dataset(path_to_splines,window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, traj, gt_poses, gt_velocity = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    ax[0].plot(y[i,:,0], y[i,:,1])\n",
    "    ax[0].quiver(y[i,::20,0],y[i,::20,1],y[i,::20,2],y[i,::20,3])\n",
    "\n",
    "ax[0].set_title(\"GT trajectories from slices of a single track\")\n",
    "ax[0].set_xlabel('x_sensor_frame')\n",
    "ax[0].set_ylabel('y_sensor_frame')\n",
    "ax[0].axis('equal')\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].set_title(\"original spline curve\")\n",
    "ax[1].plot(traj[:,0],traj[:,1])\n",
    "ax[1].scatter(gt_poses[:,0], gt_poses[:,1])\n",
    "ax[1].quiver(gt_poses[:,0], gt_poses[:,1],gt_poses[:,2], gt_poses[:,3])\n",
    "ax[1].grid()\n",
    "ax[1].axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double integration method\n",
    "\n",
    "Let's implement differentiable double integration method. Input is IMU data (ACC + GYRO) and output is piee of trajectory with a given $x_0$ and $v_0$ abounday conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider one IMU slice as an example\n",
    "imu_slice = X[0]\n",
    "# piece of trajectory we want to reconstruct\n",
    "# [x,y, cos, sin]\n",
    "traj_segment = y[0]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
    "\n",
    "ax[0].set_title('IMU slice in sensor frame')\n",
    "ax[0].plot(imu_slice[:,0],label='acc_x')\n",
    "ax[0].plot(imu_slice[:,1],label='acc_y')\n",
    "ax[0].plot(imu_slice[:,2],label='omega_z')\n",
    "ax[0].grid()\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title('gt traj segment')\n",
    "ax[1].plot(traj_segment[:,0],traj_segment[:,1])\n",
    "ax[1].quiver(traj_segment[::10,0], traj_segment[::10,1], traj_segment[::10,2],traj_segment[::10,3])\n",
    "ax[1].grid()\n",
    "ax[1].axis('equal')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def double_integrate(imu_slice, v0=torch.tensor([0,0], dtype=torch.float32)):\n",
    "    \n",
    "#     B,S,W,C = imu_slice.shape\n",
    "#     result = torch.zeros((B,S,W,4)) # result will have the same shape as input IMU data here (x,y,cos(theta),sin(theta))\n",
    "\n",
    "#     # integrating angular velocity\n",
    "\n",
    "#     heading = torch.cumsum(imu_slice[...,2],dim=-1)*1./100. # here dt = 1 #TODO this depends on sampling rate value\n",
    "\n",
    "#     result[...,2] = torch.cos(heading)\n",
    "#     result[...,3] = torch.sin(heading)\n",
    "\n",
    "#     # integrating the acc to get velocity\n",
    "#     result[...,0] = torch.cumsum(v0[:,:S,0,None] + torch.cumsum(imu_slice[...,0]*result[...,2] - imu_slice[...,1]*result[...,3],dim=-1)*1./100.,dim=-1)*1./100.\n",
    "#     result[...,1] = torch.cumsum(v0[:,:S,1,None] + torch.cumsum(imu_slice[...,0]*result[...,3] + imu_slice[...,1]*result[...,2],dim=-1)*1./100.,dim=-1)*1./100.\n",
    "\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_integrate(imu_slice, v0=torch.tensor([0,0], dtype=torch.float32)):\n",
    "    \n",
    "    B,S,W,C = imu_slice.shape\n",
    "    result = torch.zeros((B,S,W,4)) # result will have the same shape as input IMU data here (x,y,cos(theta),sin(theta))\n",
    "\n",
    "    # integrating angular velocity\n",
    "\n",
    "    # TODO add initial heading ???\n",
    "    heading = torch.cumsum(imu_slice[...,2],dim=-1)*1./100. # here dt = 1 #TODO this depends on sampling rate value\n",
    "\n",
    "    result[...,2] = torch.cos(heading.clone())\n",
    "    result[...,3] = torch.sin(heading.clone())\n",
    "\n",
    "    # integrating the acc to get velocity and trajectory\n",
    "    R = torch.stack([result[...,2],-result[...,3],result[...,3],result[...,2]],dim=-1).view(B,S,W,2,2)\n",
    "    acc = torch.matmul(R,imu_slice[...,:2].view(B,S,W,2,1)).squeeze()\n",
    "\n",
    "    v = v0[:,:S,None,:] + torch.cumsum( acc ,dim=-2)*1./100.\n",
    "\n",
    "    result[...,:2] = torch.cumsum(v,dim=-2)*1./100.\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Theseus optimization variables, cost functions and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spline motion + working from slices\n",
    "# input of the model is acc_x, acc_y and omega_z in sensor frame\n",
    "# output has the same size\n",
    "model = SimpleNN(3*window, 3*window, hid_size=300)\n",
    "model.train()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of optimization nodes in each trajectory is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = n_pts_spline_segment*n_control_points // window\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set all optimization variables, gt and cost functions in theseus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization variables for inner loop\n",
    "poses : List[th.SE2] = []\n",
    "\n",
    "# number of poses is the same as the number of nodes in trajectory\n",
    "for i in range(N):\n",
    "    poses.append(th.SE2(torch.zeros(B,3),name=f\"pose_{i}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_functions = []\n",
    "\n",
    "# adding cost factors for odometry\n",
    "for i in range(N-1):\n",
    "    # odometry measurmenets will depend on NN output\n",
    "    # pred_acc = model(input_acc[:,i].view(B,-1))  #<====== here we attach computational graph of NN to all the odometry factors via predicting acceleration\n",
    "    meas_tensor = th.SE2(torch.zeros((B,3)), name=f\"predicted_odometry_{i}\")\n",
    "\n",
    "    # meas_tensor = th.SE2(torch.tensor([gt_traj[i+1] - gt_traj[i], 0, 0]).reshape(1,-1))\n",
    "    cost_between = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_between_{i}\")\n",
    "    cost_functions.append(\n",
    "                th.Between(poses[i], poses[i+1], meas_tensor,\n",
    "                        cost_between,\n",
    "                        name=f\"between_{i}\"))\n",
    "    \n",
    "# adding cost fuctors for absolute position\n",
    "for i in range(N):\n",
    "    gt_pose_tensor = th.SE2(torch.zeros((B,3)), name=f\"gt_pose_{i}\")\n",
    "    scale_gps = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_gps_{i}\")\n",
    "    cost_functions.append(th.Difference(poses[i], gt_pose_tensor, scale_gps, name=f\"gps_{i}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding all the cost functions to the objective of inner-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = th.Objective()\n",
    "for cost in cost_functions:\n",
    "    objective.add(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what aux and optim variable the objective has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\"*40)\n",
    "print(f\"AUX variables: {len(objective.aux_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.aux_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n",
    "\n",
    "print(f\"Optimization variables: {len(objective.optim_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.optim_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining optimizer for inner loop and theseus layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.GaussNewton(\n",
    "        objective,\n",
    "        th.CholeskyDenseSolver,\n",
    "        max_iterations=10,\n",
    "        step_size=0.25, # TODO be carefull with this\n",
    "    )\n",
    "\n",
    "state_estimator = th.TheseusLayer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining helper function to update theseus inputs for every training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plotting function will update some existing figure\n",
    "# plt.ion()\n",
    "\n",
    "def plot_path(optimizer_path, groundtruth_path, y):\n",
    "    # plt.cla()\n",
    "    # plt.gca().axis(\"equal\")\n",
    "\n",
    "    # plt.xlim(-25, 25)\n",
    "    # plt.ylim(-10, 40)\n",
    "    B,S,_,_ = y.shape\n",
    "\n",
    "    root_B = int(np.sqrt(B))\n",
    "\n",
    "    assert(root_B**2 == B)\n",
    "\n",
    "    fig,ax = plt.subplots(root_B,root_B,figsize=(5*root_B,5*root_B))\n",
    "\n",
    "    b = 0\n",
    "\n",
    "    for i in range(root_B):\n",
    "        for j in range(root_B):\n",
    "            for s in range(S): #TODO add segments numbers labels\n",
    "                cos = optimizer_path[b,s][2]\n",
    "                sin = optimizer_path[b,s][3]\n",
    "                origin = optimizer_path[b,s][:2]\n",
    "                R = np.array([[cos,-sin],[sin,cos]])\n",
    "                opt_pts = torch.tensor(origin) + torch.matmul(torch.tensor(R[:,:]),y[b,s][:,:2,None]).squeeze()\n",
    "                ax[i,j].plot(opt_pts[:,0], opt_pts[:,1],color=\"tab:orange\")\n",
    "                \n",
    "            for s in range(S+1):\n",
    "                ax[i,j].text(optimizer_path[b,s][0],optimizer_path[b,s][1],f'{s}')\n",
    "            \n",
    "            ax[i,j].scatter(\n",
    "                optimizer_path[b,:,0],\n",
    "                optimizer_path[b,:,1],\n",
    "                marker=\"x\",\n",
    "                linewidth=2,\n",
    "                color=\"tab:orange\",\n",
    "                label=\"optimizer\",\n",
    "            )\n",
    "\n",
    "            #TODO add heading plt.quiver for optimized trajectory\n",
    "\n",
    "            for s in range(S):#TODO add segments numbers labels\n",
    "                cos = groundtruth_path[b,s][2]\n",
    "                sin = groundtruth_path[b,s][3]\n",
    "                origin = groundtruth_path[b,s][:2]\n",
    "                R = np.array([[cos,-sin],[sin,cos]])\n",
    "                gt_pts = torch.tensor(origin) + torch.matmul(torch.tensor(R[:,:]),y[b,s][:,:2,None]).squeeze()\n",
    "                ax[i,j].plot(gt_pts[:,0], gt_pts[:,1], color=\"tab:green\")\n",
    "\n",
    "            for s in range(S+1):\n",
    "                ax[i,j].text(groundtruth_path[b,s,0],groundtruth_path[b,s,1],f'{s}')\n",
    "                \n",
    "            ax[i,j].scatter(\n",
    "                groundtruth_path[b,:,0],\n",
    "                groundtruth_path[b,:,1],\n",
    "                marker='x',\n",
    "                linewidth=2,\n",
    "                color=\"tab:green\",\n",
    "                label=\"groundtruth\",\n",
    "            )\n",
    "\n",
    "            #TODO add heading plt.quiver for gt trajectory\n",
    "            for s in range(S+1):\n",
    "                ax[i,j].plot([optimizer_path[b,s,0],groundtruth_path[b,s,0]],[optimizer_path[b,s,1],groundtruth_path[b,s,1]],'-',color='red')\n",
    "\n",
    "            ax[i,j].grid()\n",
    "            ax[i,j].legend()\n",
    "            ax[i,j].axis('equal')\n",
    "            b = b+1\n",
    "\n",
    "\n",
    "    plt.suptitle(f\"mean squared error {F.mse_loss(torch.tensor(optimizer_path),groundtruth_path)}\")\n",
    "    # TODO add error for all individual samples\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.pause(1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataloader for our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=dataset, batch_size=B, shuffle=not True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "losses = []\n",
    "\n",
    "theseus_inputs = {}\n",
    "\n",
    "for i in range(N):\n",
    "    theseus_inputs[f\"pose_{i}\"] = th.SE2(torch.zeros(B, 3)).tensor\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "\n",
    "            input_acc, y, gt_traj, gt_pose, gt_velocity = data[0],data[1],data[2],data[3],data[4]\n",
    "        \n",
    "            model_optimizer.zero_grad()\n",
    "\n",
    "            # preparing theseus inputs\n",
    "            # we ran input acc signals through the NN and get some output acc values (NN model is our observation function)\n",
    "            # after model inference we do manual integration of model output - tensor graph should preserved\n",
    "\n",
    "            # predicted_odometry = run_model(model, input_acc)\n",
    "            predicted_acc = model(input_acc.view(-1,300)).view(input_acc.shape)\n",
    "        \n",
    "            # doing manual double integration here\n",
    "            predicted_odometry = double_integrate(predicted_acc, gt_velocity)\n",
    "            \n",
    "            for j in range(N-1):\n",
    "                tmp = predicted_odometry[:,j,-1,:]\n",
    "                theseus_inputs[f\"predicted_odometry_{j}\"] = th.SE2(tensor = tmp)\n",
    "\n",
    "            # here we update AUX variables (predicted incremental poses updated here\n",
    "            \n",
    "            for j in range(N):\n",
    "                theseus_inputs[f\"gt_pose_{j}\"] = th.SE2(tensor = gt_pose[:,j])\n",
    "\n",
    "            objective.update(theseus_inputs)\n",
    "            print(f\"Objective error = {objective.error_metric().mean().item()}\")\n",
    "\n",
    "            # inner loop optimization runs here\n",
    "            # inner loop optimization result will be store into the theseus_inputs dictionary (pose_i - objects - optimization variables)\n",
    "            theseus_outputs, _ = state_estimator.forward(\n",
    "                        theseus_inputs,\n",
    "                        optimizer_kwargs={\n",
    "                            \"track_best_solution\": True,\n",
    "                            \"verbose\": epoch % 1 == 0,\n",
    "                        },\n",
    "                    )\n",
    "\n",
    "            # here we transform trajectory from optimizator\n",
    "            optimized_path = torch.zeros((B,N,4))\n",
    "            for i in range(N):\n",
    "                optimized_path[:, i] = theseus_outputs[f\"pose_{i}\"]\n",
    "\n",
    "\n",
    "            gt_path = torch.zeros((B,N,4))\n",
    "            for i in range(N):\n",
    "                gt_path[:, i] = gt_pose[:,i]\n",
    "\n",
    "            # calculating mse_loss function between trajectories\n",
    "            mse_loss = F.mse_loss(optimized_path.squeeze(), gt_path.squeeze(),reduction='none').mean(axis=0).mean()\n",
    "            loss = mse_loss\n",
    "            \n",
    "            loss.backward(retain_graph=True) # we need to retain_grad to keep graph for gradient calculation or not if everything is initialized in theseus_inputs for inner_loop\n",
    "\n",
    "            # updating model weights\n",
    "            model_optimizer.step()\n",
    "\n",
    "            print(model.fc[0].weight)\n",
    "\n",
    "            # saving loss valuesdouble_integrate\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # visualizing the GT and optimized trajectory\n",
    "        if epoch % 2 == 0:\n",
    "            plot_path(optimized_path.squeeze().detach().numpy(), gt_pose, y)\n",
    "            pass\n",
    "\n",
    "\n",
    "print(losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses)\n",
    "plt.title(\"Train losses\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D\n",
    "1)  additive noise to acc, multiplicative noise to acc\n",
    "2) work from slices\n",
    "\n",
    "\n",
    "full SE2\n",
    "SE2\n",
    "NN_input: slice of acc_x[window] and gyro_z[window]\n",
    "NN_output: delta_v, delta_angle (scalars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theseus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
