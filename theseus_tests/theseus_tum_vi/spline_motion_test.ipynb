{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import theseus as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from spline_generation import generate_batch_of_splines\n",
    "from spline_dataloader import Spline_2D_Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple MLP model for initial tests\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hid_size=30, use_offset=False):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, out_size, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_):\n",
    "        return self.fc(state_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "Generating 2d data - moving along spline curve on a 2D plane.\n",
    "\n",
    "Generatint batch of data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_splines = \"./splines/\"\n",
    "\n",
    "B = 4 # number of splines in batch\n",
    "n_batch = 1 # number of batches to generate\n",
    "n_control_points = 5 # number of control points in spline. Matches number of poses in optimization problem\n",
    "n_pts_spline_segment = 100 # number of points for each spline segment during interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_batch_of_splines(path_to_splines, B*n_batch, n_control_points, n_pts_spline_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "dataset = Spline_2D_Dataset(path_to_splines,window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "X, y, traj, gt_poses, gt_velocity = dataset.__getitem__(3)\n",
    "for i in range(X.shape[0]):\n",
    "    plt.plot(y[i,:,0], y[i,:,1])\n",
    "    plt.quiver(y[i,::20,0],y[i,::20,1],y[i,::20,2],y[i,::20,3])\n",
    "\n",
    "plt.title(\"GT trajectories from slices of a single track\")\n",
    "# plt.axis('equal')\n",
    "plt.xlabel('x_sensor_frame')\n",
    "plt.ylabel('y_sensor_frame')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"original spline curve\")\n",
    "plt.plot(traj[:,0],traj[:,1])\n",
    "plt.scatter(gt_poses[:,0], gt_poses[:,1])\n",
    "plt.quiver(gt_poses[:,0], gt_poses[:,1],gt_poses[:,2], gt_poses[:,3])\n",
    "plt.grid()\n",
    "plt.axis('equal')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double integration method\n",
    "\n",
    "Let's implement differentiable double integration method. Input is IMU data (ACC + GYRO) and output is piee of trajectory with a given $x_0$ and $v_0$ abounday conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider one IMU slice as an example\n",
    "imu_slice = X[1]\n",
    "plt.figure()\n",
    "plt.title('IMU slice in sensor frame')\n",
    "plt.plot(imu_slice[:,0],label='acc_x')\n",
    "plt.plot(imu_slice[:,1],label='acc_y')\n",
    "plt.plot(imu_slice[:,2],label='omega_z')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piece of trajectory we want to reconstruct\n",
    "# [x,y, cos, sin]\n",
    "traj_segment = y[1]\n",
    "plt.figure()\n",
    "plt.plot(traj_segment[:,0],traj_segment[:,1])\n",
    "plt.quiver(traj_segment[::10,0], traj_segment[::10,1], traj_segment[::10,2],traj_segment[::10,3])\n",
    "plt.grid()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def double_integrate(imu_slice, v0=torch.tensor([0,0], dtype=torch.float32)):\n",
    "    \n",
    "#     B,S,W,C = imu_slice.shape\n",
    "#     result = torch.zeros((B,S,W,4)) # result will have the same shape as input IMU data here (x,y,cos(theta),sin(theta))\n",
    "\n",
    "#     # integrating angular velocity\n",
    "\n",
    "#     heading = torch.cumsum(imu_slice[...,2],dim=-1)*1./100. # here dt = 1 #TODO this depends on sampling rate value\n",
    "\n",
    "#     result[...,2] = torch.cos(heading)\n",
    "#     result[...,3] = torch.sin(heading)\n",
    "\n",
    "#     # integrating the acc to get velocity\n",
    "#     result[...,0] = torch.cumsum(v0[:,:S,0,None] + torch.cumsum(imu_slice[...,0]*result[...,2] - imu_slice[...,1]*result[...,3],dim=-1)*1./100.,dim=-1)*1./100.\n",
    "#     result[...,1] = torch.cumsum(v0[:,:S,1,None] + torch.cumsum(imu_slice[...,0]*result[...,3] + imu_slice[...,1]*result[...,2],dim=-1)*1./100.,dim=-1)*1./100.\n",
    "\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_integrate(imu_slice, v0=torch.tensor([0,0], dtype=torch.float32)):\n",
    "    \n",
    "    B,S,W,C = imu_slice.shape\n",
    "    result = torch.zeros((B,S,W,4)) # result will have the same shape as input IMU data here (x,y,cos(theta),sin(theta))\n",
    "\n",
    "    # integrating angular velocity\n",
    "\n",
    "    heading = torch.cumsum(imu_slice[...,2],dim=-1)*1./100. # here dt = 1 #TODO this depends on sampling rate value\n",
    "\n",
    "    result[...,2] = torch.cos(heading)\n",
    "    result[...,3] = torch.sin(heading)\n",
    "\n",
    "\n",
    "    # integrating the acc to get velocity and trajectory\n",
    "    R = torch.stack([result[...,2],-result[...,3],result[...,3],result[...,2]],dim=-1).view(B,S,W,2,2)\n",
    "    acc = torch.matmul(R,imu_slice[...,:2].view(B,S,W,2,1)).squeeze()\n",
    "\n",
    "    v = v0[:,:S,None,:] + torch.cumsum( acc ,dim=-2)*1./100.\n",
    "\n",
    "    result[...,:2] = torch.cumsum(v,dim=-2)*1./100.\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed = double_integrate(imu_slice,gt_velocity[1])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(traj_segment[:,0],traj_segment[:,1])\n",
    "# plt.quiver(traj_segment[::10,0], traj_segment[::10,1], traj_segment[::10,2],traj_segment[::10,3])\n",
    "\n",
    "\n",
    "# plt.plot(reconstructed[:,0],reconstructed[:,1])\n",
    "# plt.quiver(reconstructed[::10,0], reconstructed[::10,1], reconstructed[::10,2],reconstructed[::10,3])\n",
    "# plt.grid()\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Theseus optimization variables, cost functions and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spline motion + working from slices\n",
    "# input of the model is acc_x, acc_y and omega_z in sensor frame\n",
    "# output has the same size\n",
    "model = SimpleNN(window*3, 3*window, hid_size=300)\n",
    "model.train()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of optimization nodes in each trajectory is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = n_pts_spline_segment*n_control_points // window\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set all optimization variables, gt and cost functions in theseus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization variables for inner loop\n",
    "poses : List[th.SE2] = []\n",
    "\n",
    "# number of poses is the same as the number of nodes in trajectory\n",
    "for i in range(N):\n",
    "    poses.append(th.SE2(torch.zeros(B,3),name=f\"pose_{i}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_functions = []\n",
    "\n",
    "# adding cost factors for odometry\n",
    "for i in range(N-1):\n",
    "    # odometry measurmenets will depend on NN output\n",
    "    # pred_acc = model(input_acc[:,i].view(B,-1))  #<====== here we attach computational graph of NN to all the odometry factors via predicting acceleration\n",
    "    meas_tensor = th.SE2(torch.zeros((B,3)), name=f\"predicted_odometry_{i}\")\n",
    "\n",
    "    # meas_tensor = th.SE2(torch.tensor([gt_traj[i+1] - gt_traj[i], 0, 0]).reshape(1,-1))\n",
    "    cost_between = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_between_{i}\")\n",
    "    cost_functions.append(\n",
    "                th.Between(poses[i], poses[i+1], meas_tensor,\n",
    "                        cost_between,\n",
    "                        name=f\"between_{i}\"))\n",
    "    \n",
    "# adding cost fuctors for absolute position\n",
    "for i in range(N):\n",
    "    gt_pose_tensor = th.SE2(torch.zeros((B,3)), name=f\"gt_pose_{i}\")\n",
    "    scale_gps = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_gps_{i}\")\n",
    "    cost_functions.append(th.Difference(poses[i], gt_pose_tensor, scale_gps, name=f\"gps_{i}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding all the cost functions to the objective of inner-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = th.Objective()\n",
    "for cost in cost_functions:\n",
    "    objective.add(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what aux and optim variable the objective has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\"*40)\n",
    "print(f\"AUX variables: {len(objective.aux_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.aux_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n",
    "\n",
    "print(f\"Optimization variables: {len(objective.optim_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.optim_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining optimizer for inner loop and theseus layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.GaussNewton(\n",
    "        objective,\n",
    "        th.CholeskyDenseSolver,\n",
    "        max_iterations=3,\n",
    "        step_size=0.1,\n",
    "    )\n",
    "\n",
    "state_estimator = th.TheseusLayer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining helper function to update theseus inputs for every training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plotting function will update some existing figure\n",
    "plt.ion()\n",
    "\n",
    "def plot_path(optimizer_path, groundtruth_path):\n",
    "    plt.cla()\n",
    "    # plt.gca().axis(\"equal\")\n",
    "\n",
    "    # plt.xlim(-25, 25)\n",
    "    # plt.ylim(-10, 40)\n",
    "    B = optimizer_path.shape[0]\n",
    "\n",
    "    for b in range(B):\n",
    "        plt.plot(\n",
    "            optimizer_path[b,:,0],\n",
    "            optimizer_path[b,:,1],\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:orange\",\n",
    "            label=\"optimizer\",\n",
    "        )\n",
    "\n",
    "        #TODO add heading plt.quiver for optimized trajectory\n",
    "\n",
    "\n",
    "        plt.plot(\n",
    "            groundtruth_path[b,:,0],\n",
    "            groundtruth_path[b,:,1],\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:green\",\n",
    "            label=\"groundtruth\",\n",
    "        )\n",
    "\n",
    "        #TODO add heading plt.quiver for gt trajectory\n",
    "\n",
    "    plt.title(f\"mean squared error {F.mse_loss(torch.tensor(optimizer_path),groundtruth_path)}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.pause(1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataloader for our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=dataset, batch_size=B, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "\n",
    "losses = []\n",
    "\n",
    "theseus_inputs = {}\n",
    "\n",
    "for i in range(N):\n",
    "    theseus_inputs[f\"pose_{i}\"] = th.SE2(torch.zeros(B, 3)).tensor\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "\n",
    "            input_acc, y, _, gt_pose, gt_velocity = data[0],data[1],data[2],data[3],data[4]\n",
    "        \n",
    "            model_optimizer.zero_grad()\n",
    "\n",
    "            # preparing theseus inputs\n",
    "            # we ran input acc signals through the NN and get some output acc values (NN model is our observation function)\n",
    "            # after model inference we do manual integration of model output - tensor graph should preserved\n",
    "\n",
    "            # predicted_odometry = run_model(model, input_acc)\n",
    "            predicted_acc = model(input_acc.view(-1,300)).view(input_acc.shape)\n",
    "\n",
    "            kek = double_integrate(predicted_acc,gt_velocity)\n",
    "        \n",
    "            # doing manual double integration here\n",
    "            theseus_inputs = {}\n",
    "            for j in range(N-1):\n",
    "                theseus_inputs[f\"predicted_odometry_{j}\"] = th.SE2(tensor=torch.tensor(kek[:,j,-1,:],requires_grad=True))\n",
    "\n",
    "            # here we update AUX variables (predicted incremental poses updated here\n",
    "            # theseus_inputs['scale_between_0'] = torch.ones((B,1))\n",
    "            # theseus_inputs['scale_gps_0'] = torch.ones((B,1))\n",
    "            # theseus_inputs['scale_gps_1'] = torch.ones((B,1))\n",
    "            # theseus_inputs['gt_pose_0'] = F.pad(gt_traj[:,0].view(B,-1), pad=(0,2))\n",
    "            # theseus_inputs['gt_pose_1'] = F.pad(gt_traj[:,1].view(B,-1), pad=(0,2))\n",
    "\n",
    "            objective.update(theseus_inputs)\n",
    "            print(f\"Objective error = {objective.error_metric().mean().item()}\")\n",
    "\n",
    "            # # checking that the number of variables not gowing\n",
    "            # print(\"+\"*40)\n",
    "            # print(f\"AUX variables: {len(objective.aux_vars)}\")\n",
    "            # print(\"+\"*40)\n",
    "            # for c in objective.aux_vars:\n",
    "            #     print(c)\n",
    "            # print(\"+\"*40)\n",
    "\n",
    "            # print(f\"Optimization variables: {len(objective.optim_vars)}\")\n",
    "            # print(\"+\"*40)\n",
    "            # for c in objective.optim_vars:\n",
    "            #     print(c)\n",
    "            # print(\"+\"*40)\n",
    "\n",
    "            # inner loop optimization is here\n",
    "            # inner loop optimization result will be store into the theseus_inputs dictionary (pose_i - objects - optimization variables)\n",
    "            theseus_output, _ = state_estimator.forward(\n",
    "                    theseus_inputs,\n",
    "                    optimizer_kwargs={\n",
    "                        \"track_best_solution\": True,\n",
    "                        \"verbose\": epoch % 1 == 0,\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            # here we transform trajectory from optimizator\n",
    "            optimized_path = torch.zeros((B,N,4))\n",
    "            for i in range(N):\n",
    "                optimized_path[:, i] = theseus_output[f\"pose_{i}\"]\n",
    "\n",
    "            gt_path = torch.zeros((B,N,4))\n",
    "            for i in range(N):\n",
    "                gt_path[:, i] = gt_pose[:,i]\n",
    "\n",
    "            # calculating mse_loss function between trajectories\n",
    "            mse_loss = F.mse_loss(optimized_path.squeeze(), gt_path.squeeze(),reduction='none').mean(axis=0).mean()\n",
    "            loss = mse_loss\n",
    "            \n",
    "            loss.backward(retain_graph=True) # we need to retain_grad to keep graph for gradient calculation\n",
    "\n",
    "            # updating model weights\n",
    "            model_optimizer.step()\n",
    "\n",
    "            # saving loss values\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # visualizing the GT and optimized trajectory\n",
    "            if epoch % 2 == 0:\n",
    "                plot_path(optimized_path.squeeze().detach().numpy(), gt_pose)\n",
    "\n",
    "print(losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses)\n",
    "plt.title(\"Train losses\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D\n",
    "1)  additive noise to acc, multiplicative noise to acc\n",
    "2) work from slices\n",
    "\n",
    "\n",
    "full SE2\n",
    "SE2\n",
    "NN_input: slice of acc_x[window] and gyro_z[window]\n",
    "NN_output: delta_v, delta_angle (scalars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theseus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
