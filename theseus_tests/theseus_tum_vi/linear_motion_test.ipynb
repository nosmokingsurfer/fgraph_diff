{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theseus as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from tqdm import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple MLP model for initial tests\n",
    "# in our initial 1-D test the input and output of the model will be 1 dimentional\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, in_size, out_size, hid_size=30, use_offset=False):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, out_size, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, state_):\n",
    "        return self.fc(state_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "Generating 1d data - random acceleration along 1 axis. No rotation or motion along other axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(B = 1, N = 10):\n",
    "    return torch.randn((B,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 4 # number of trajectories in batch\n",
    "N = 100 # number of trajectory points\n",
    "\n",
    "# window = 5\n",
    "\n",
    "# generating random acceleration\n",
    "input_acc = generate_data(B,N)\n",
    "for i in range(B):\n",
    "    plt.plot(input_acc[i,:], label=f'noiseless acc {i}')\n",
    "\n",
    "# velocity dt = 1 sec\n",
    "gt_vel = torch.cumsum(input_acc, dim=-1)\n",
    "\n",
    "for i in range(B):\n",
    "    plt.plot(gt_vel[i],label=f'gt velocity {i}')\n",
    "\n",
    "# trjectory dt = 1sec\n",
    "gt_traj = torch.cumsum(gt_vel, dim=-1)\n",
    "\n",
    "\n",
    "# additive noise\n",
    "# input_acc = input_acc + 2*torch.randn((B,N))\n",
    "\n",
    "# multiplicative noise\n",
    "# input_acc = input_acc*2*torch.randn((B,N))\n",
    "\n",
    "for i in range(B):\n",
    "    plt.plot(input_acc[i], label=f'acc + noise {i}')\n",
    "plt.title(\"Synthetic data\")\n",
    "# plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "for i in range(B):\n",
    "    plt.plot(gt_traj[i], label=f'gt traj {i}')\n",
    "plt.title('GT X trajectory')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Theseus optimization variables, cost functions and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d task - only moving along X axis w/o any rotation\n",
    "model = SimpleNN(1, 1, hid_size=30)\n",
    "model.train()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set all optimization variables, gt and cost functions in theseus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization variables for inner loop\n",
    "poses : List[th.SE2] = []\n",
    "\n",
    "# number of poses is the same as the number of nodes in trajectory\n",
    "for i in range(N):\n",
    "    poses.append(th.SE2(torch.zeros(B,3),name=f\"pose_{i}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_functions = []\n",
    "\n",
    "# adding cost factors for odometry\n",
    "for i in range(N-1):\n",
    "    # odometry measurmenets will depend on NN output\n",
    "    # pred_acc = model(input_acc[:,i].view(B,-1))  #<====== here we attach computational graph of NN to all the odometry factors via predicting acceleration\n",
    "    meas_tensor = th.SE2(torch.zeros((B,3)), name=f\"predicted_odometry_{i}\")\n",
    "\n",
    "    # meas_tensor = th.SE2(torch.tensor([gt_traj[i+1] - gt_traj[i], 0, 0]).reshape(1,-1))\n",
    "    cost_between = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_between_{i}\")\n",
    "    cost_functions.append(\n",
    "                th.Between(poses[i], poses[i+1], meas_tensor,\n",
    "                        cost_between,\n",
    "                        name=f\"between_{i}\"))\n",
    "    \n",
    "# adding cost fuctors for absolute position\n",
    "for i in range(N):\n",
    "    gt_pose_tensor = th.SE2(F.pad(gt_traj[:,i].view(B,-1), pad=(0,2)), name=f\"gt_pose_{i}\")\n",
    "    scale_gps = th.ScaleCostWeight(torch.ones((B,1)), name=f\"scale_gps_{i}\")\n",
    "    cost_functions.append(th.Difference(poses[i], gt_pose_tensor, scale_gps, name=f\"gps_{i}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding all the cost functions to the objective of inner-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = th.Objective()\n",
    "for cost in cost_functions:\n",
    "    objective.add(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what aux and optim variable the objective has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\"*40)\n",
    "print(f\"AUX variables: {len(objective.aux_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.aux_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n",
    "\n",
    "print(f\"Optimization variables: {len(objective.optim_vars)}\")\n",
    "print(\"+\"*40)\n",
    "for c in objective.optim_vars:\n",
    "    print(c)\n",
    "print(\"+\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining optimizer for inner loop and theseus layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.GaussNewton(\n",
    "        objective,\n",
    "        th.CholeskyDenseSolver,\n",
    "        max_iterations=3,\n",
    "        step_size=0.1,\n",
    "    )\n",
    "\n",
    "state_estimator = th.TheseusLayer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining helper function to update theseus inputs for every training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plotting function will update some existing figure\n",
    "plt.ion()\n",
    "\n",
    "def plot_path(optimizer_path, groundtruth_path):\n",
    "    plt.cla()\n",
    "    # plt.gca().axis(\"equal\")\n",
    "\n",
    "    # plt.xlim(-25, 25)\n",
    "    # plt.ylim(-10, 40)\n",
    "\n",
    "    batch_idx = 0\n",
    "    for i in range(B):\n",
    "        plt.plot(\n",
    "            optimizer_path[i],\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:orange\",\n",
    "            label=\"optimizer\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            groundtruth_path[i],\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:green\",\n",
    "            label=\"groundtruth\",\n",
    "        )\n",
    "    plt.title(f\"mean squared error {F.mse_loss(torch.tensor(optimizer_path),groundtruth_path)}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.pause(1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "\n",
    "losses = []\n",
    "\n",
    "with torch.autograd.detect_anomaly():\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        model_optimizer.zero_grad()\n",
    "\n",
    "        # preparing theseus inputs\n",
    "        # we ran input acc signals through the NN and get some output acc values (NN model is our observation function)\n",
    "        # after model inference we do manual integration of model output - tensor graph should preserved\n",
    "\n",
    "        # predicted_odometry = run_model(model, input_acc)\n",
    "        predicted_acc = model(input_acc.view(-1,1)).view(B,-1)\n",
    "    \n",
    "        # doing manual double integration here\n",
    "        theseus_inputs = {}\n",
    "        for i in range(N-1):\n",
    "            tmp = torch.zeros(4,4)\n",
    "            tmp[:,2] =  1.0\n",
    "            tmp[:,0] = 0.5*predicted_acc[:,i]**2 + predicted_acc[:,i]\n",
    "            theseus_inputs[f\"predicted_odometry_{i}\"] = tmp\n",
    "\n",
    "        # here we update AUX variables (predicted incremental poses updated here\n",
    "        # theseus_inputs['scale_between_0'] = torch.ones((B,1))\n",
    "        # theseus_inputs['scale_gps_0'] = torch.ones((B,1))\n",
    "        # theseus_inputs['scale_gps_1'] = torch.ones((B,1))\n",
    "        # theseus_inputs['gt_pose_0'] = F.pad(gt_traj[:,0].view(B,-1), pad=(0,2))\n",
    "        # theseus_inputs['gt_pose_1'] = F.pad(gt_traj[:,1].view(B,-1), pad=(0,2))\n",
    "\n",
    "        objective.update(theseus_inputs)\n",
    "        print(f\"Objective error = {objective.error_metric().mean().item()}\")\n",
    "\n",
    "        # # checking that the number of variables not gowing\n",
    "        # print(\"+\"*40)\n",
    "        # print(f\"AUX variables: {len(objective.aux_vars)}\")\n",
    "        # print(\"+\"*40)\n",
    "        # for c in objective.aux_vars:\n",
    "        #     print(c)\n",
    "        # print(\"+\"*40)\n",
    "\n",
    "        # print(f\"Optimization variables: {len(objective.optim_vars)}\")\n",
    "        # print(\"+\"*40)\n",
    "        # for c in objective.optim_vars:\n",
    "        #     print(c)\n",
    "        # print(\"+\"*40)\n",
    "\n",
    "        # inner loop optimization is here\n",
    "        # inner loop optimization result will be store into the theseus_inputs dictionary (pose_i - objects - optimization variables)\n",
    "        theseus_output, _ = state_estimator.forward(\n",
    "                theseus_inputs,\n",
    "                optimizer_kwargs={\n",
    "                    \"track_best_solution\": True,\n",
    "                    \"verbose\": epoch % 1 == 0,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        # here we transform trajectory from optimizator\n",
    "        optimized_path = torch.zeros((B,N,1))\n",
    "        for i in range(N):\n",
    "            optimized_path[:, i] = theseus_output[f\"pose_{i}\"][:,0].reshape(B,1)\n",
    "\n",
    "        gt_path = torch.zeros((B,N,1))\n",
    "        for i in range(N):\n",
    "            gt_path[:, i, 0] = gt_traj[:,i]\n",
    "\n",
    "        # calculating mse_loss function between trajectories\n",
    "        mse_loss = F.mse_loss(optimized_path.squeeze(), gt_path.squeeze(),reduction='none').mean(axis=1).mean()\n",
    "        loss = mse_loss\n",
    "        \n",
    "        loss.backward() # we need to retain_grad to keep graph for gradient calculation\n",
    "\n",
    "        # updating model weights\n",
    "        model_optimizer.step()\n",
    "\n",
    "        # saving loss values\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # visualizing the GT and optimized trajectory\n",
    "        if epoch % 2 == 0:\n",
    "            pass\n",
    "            # plot_path(optimized_path.squeeze().detach().numpy(), gt_traj)\n",
    "\n",
    "print(losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses)\n",
    "plt.title(\"Train losses\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D\n",
    "1)  additive noise to acc, multiplicative noise to acc\n",
    "2) work from slices\n",
    "\n",
    "\n",
    "full SE2\n",
    "SE2\n",
    "NN_input: slice of acc_x[window] and gyro_z[window]\n",
    "NN_output: delta_v, delta_angle (scalars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theseus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
